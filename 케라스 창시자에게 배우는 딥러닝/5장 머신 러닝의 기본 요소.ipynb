{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236f4552",
   "metadata": {},
   "source": [
    "## 5.1 일반화 : 머신 러닝의 목표\n",
    "## 5.2 머신 러닝 모델 평가\n",
    "## 5.3 훈련 성능 향상하기\n",
    "## 5.4 일반화 성능 향상하기\n",
    "## 5.5 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b8e79",
   "metadata": {},
   "source": [
    "## 5.1 일반화 : 머신 러닝의 목표\n",
    "#### 최적화 : 가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정(머신러닝)\n",
    "#### 일반화 : 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행하는지\n",
    "### 과소적합과 과대적합\n",
    "- 잡음 섞인 훈련 데이터\n",
    "\n",
    "    ㄴ 모델을 이런 이상치에 맞추려고 하면 일반화 성능 감소\n",
    "    \n",
    "- 불확실한 특성\n",
    "\n",
    "    ㄴ 특성 공간의 모호한 영역에 너무 확신을 가지면 과대적합 발생\n",
    "    \n",
    "- 드문 특성과 가짜 상관관계\n",
    "    \n",
    "    ㄴ 드문 특성 값을 포함한 데이터셋에서 훈련한 멋니 러닝 모델은 과대적합될 가능성 ↑\n",
    "    \n",
    "#### 잡음 특성은 필연적으로 과대적합을 유발시킨다. 따라서 특성이 모델에 유익한지 또는 모델을 혼란스럽게 만드는지 확실하지 않다면 훈련 전에 #### \n",
    "### 특성 선택 ###\n",
    "#### 을 수행하는 것이 일반적\n",
    "### 딥러닝에서 일반화의 본질\n",
    "- 매니폴드 가설\n",
    "\n",
    "    ㄴ 기술적으로 손글씨 숫자가 가능한 모든 28x28 unit8 배열로 이루어진 공간 안에서 **매니폴드**를 형성한다고 한다\n",
    "    \n",
    "    ㄴ **매니폴드** : 국부적으로 선형(유클리드) 공간과 비슷하게 보이는 부모 공간의 저차원 부분 공간\n",
    "    \n",
    "    ㄴ **매니폴드 가설** : 실제 세상의 모든 데이터가 (이 데이터가 인코딩된) 고차원 공간 안에 있는 저차원 매니폴드에 놓여 있다고 가정\n",
    "    \n",
    "    ㄴ **매니폴드 가설 의미** : 1. 머신 러닝 모델은 가능한 입력 공간 안에서 비교적 간단하고, 저차원이며, 매우 구조적인 부분 공간(잠재 매니폴드)만 학습하면 된다. 2. 이런 매니폴드 중 하낭 안에서 두 입력 사이를 보간하는 것이 항상 가능하다. 즉, 연속적인 경로를 따라 한 입력에서 다른 입력으로 변형할 때 모든 포인트가 이 매니폴드에 속한다.\n",
    "    \n",
    "- 일반화의 원천인 보간\n",
    "\n",
    "    ㄴ 다루는 데이터 포인트를 **보간**할 수 있다면 이전에 본 적 없는 포인트를 해당 매니폴드에서 가까이 놓인 다른 포인트와 연결하여 이해할 수 있다. 다른 말로 하면 공간 안의 샘플만 사용해서 공간 전체를 이해할 수 있다. **보간**을 사용해서 빈 곳을 채울 수 있기 때문이다.\n",
    "    \n",
    "#### 근사적으로 학습된 데이터 매니폴드에서 보간을 통해 딥러닝의 일반화가 달성되지만 보간이 일반화의 전부라고 가정하는 것은 실수!####\n",
    "=> 이는 **지역 일반화**\n",
    "\n",
    "- 딥러닝이 작동하는 이유\n",
    "\n",
    "    ㄴ 딥러닝은 본질적으로 크고 복잡한 곡선(매니폴드)을 선택하여 훈련 데이터 포인트에 맞을 때 까지 파라미터를 점진적으로 조정하는 것\n",
    "    \n",
    "- 가장 중요한 훈련 데이터\n",
    "\n",
    "    ㄴ 딥러닝이 실제로 매니폴드 학습에 잘 맞지만 일반화의 능력은 모델의 어떤 속성 때문이라기보다 데이터의 자연적인 구조로 인한 결과\n",
    "    \n",
    "    ㄴ 데이터가 보간할 수 있는 매니폴드를 형성하는 경우에만 일반화 할 수 o\n",
    "    ㄴ **조밀한 샘플링** : 학습된 모델이 잠재 공간을 잘 근사하고 보간을 통해 일반화를 달성\n",
    "    \n",
    "#### 따라서 딥러닝 모델을 향상시키는 가장 좋은 방법은 더 좋고, 더 많은 데이터에서 훈련하는 것이라는 점!! ####\n",
    "\n",
    "## 5.2 머신 러닝 모델 평가\n",
    "### 훈련, 검증, 테스트 세트\n",
    "- 단순 홀드아웃 검증\n",
    "- K-겹 교차 검증\n",
    "- 셔플링을 사용한 반복 K-겹 교차 검증\n",
    "### 상식 수준의 기준점 넘기\n",
    "### 모델 평가에 대해 유념해야 할 점\n",
    "- 대표성 있는 데이터\n",
    "- 시간의 방향\n",
    "- 데이터 중복\n",
    "\n",
    "## 5.3 훈련 성능 향상하기\n",
    "### 경사 하강법의 핵심 파라미터 튜닝하기\n",
    "### 구조에 대해 더 나은 가정하기\n",
    "### 모델 용량 늘리기\n",
    "\n",
    "## 5.4 일반화 성능 향상하기\n",
    "### 데이터셋 큐레이션\n",
    "### 특성 공학\n",
    "### 조기 종료 사용하기\n",
    "### 모델 규제하기\n",
    "- 가중치 규제 추가\n",
    "- 드롭아웃 추가\n",
    "\n",
    "## 5.5 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca9e24",
   "metadata": {},
   "source": [
    "### validation data를 test로 쓸 수 없는 이유?\n",
    "\n",
    "- validation data는 하이퍼파라미터를 조정하는데 도움을 준다.\n",
    "\n",
    "- 그럼 validation data를 사용해서 최적화된 하이퍼파라미터를 만들어주었는데, \n",
    "\n",
    "#### => 검증 데이터로 맞추어 최적화했기 때문에 검증 데이터에 의도적으로 잘 수행되는 모델이 만들어진다. ####\n",
    "\n",
    "이걸 test로 쓰면 **정보누설**\n",
    "\n",
    "번외로,\n",
    "\n",
    "train data 역시 test로 쓸 수 없다.\n",
    "\n",
    "왜냐, train data는 파라미터(W 가중치)를 조정하는데 쓰이기 때문에\n",
    "\n",
    "이 역시 train 데이터로 맞추어 최적화된 가중치를 만들었기 때문에 test로 쓰이면 의미가 없다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
